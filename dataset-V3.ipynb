{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b6749d87-03be-4447-a7cd-d129bb77c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c81207-d13c-46c4-abc7-43ed7ce3c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_log_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(';')\n",
    "            \n",
    "            if len(parts) != 5:\n",
    "                continue  \n",
    "            \n",
    "            id = parts[0].strip()\n",
    "            timestamps_str = parts[1].strip().strip('[]')\n",
    "            try:\n",
    "                if timestamps_str and all(part.isdigit() for part in timestamps_str.split(', ')):\n",
    "                    timestamps = list(map(int, timestamps_str.split(', ')))\n",
    "                else:\n",
    "                    timestamps = []\n",
    "            except ValueError:\n",
    "                timestamps = []\n",
    "                \n",
    "            fqdn_list_str = parts[2].strip().strip('[]')\n",
    "            if fqdn_list_str:\n",
    "                fqdn_list = [fqdn.strip(\"'\\\"\") for fqdn in fqdn_list_str.split(', ')]\n",
    "            else:\n",
    "                fqdn_list = []\n",
    "            \n",
    "            status_list_str = parts[3].strip().strip('[]')\n",
    "            if status_list_str:\n",
    "                status_list = [status.strip(\"'\\\"\") for status in status_list_str.split(', ')]\n",
    "            else:\n",
    "                status_list = []\n",
    "            \n",
    "            output_status = parts[4].strip()\n",
    "            \n",
    "            data.append((id, timestamps, fqdn_list, status_list, output_status))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f466b8a-b4e6-4cef-9873-873c9e82a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(s):\n",
    "    probabilities = [float(s.count(c)) / len(s) for c in dict.fromkeys(list(s))]\n",
    "    entropy = - sum([p * np.log2(p) for p in probabilities])\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eeb0ad06-22e2-422a-a535-01b3bc6fcd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data):\n",
    "    dataset = {\n",
    "        'ID': [],\n",
    "        'Timestamp': [],\n",
    "        'FQDNs': [],\n",
    "        'Status': [],\n",
    "        'Output': []\n",
    "    }\n",
    "\n",
    "    for entry in data:\n",
    "        id, timestamps, fqdn_list, status_list, output_status = entry\n",
    "        dataset['ID'].append(id)\n",
    "        dataset['Timestamp'].append(timestamps)\n",
    "        dataset['FQDNs'].append(fqdn_list)\n",
    "        dataset['Status'].append(status_list)\n",
    "        dataset['Output'].append(output_status)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66f7385e-6fdd-4e07-9eaf-a6fd3e15f664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(dataset):\n",
    "    features = []\n",
    "    for i in range(len(dataset['ID'])):\n",
    "        id = dataset['ID'][i]\n",
    "        timestamps = dataset['Timestamp'][i]\n",
    "        fqdn_list = dataset['FQDNs'][i]\n",
    "        status_list = dataset['Status'][i]\n",
    "        output_status = dataset['Output'][i]  # Retrieve the Output status\n",
    "        \n",
    "        # Calculate inter-arrival times (IAT)\n",
    "        if len(timestamps) > 1:\n",
    "            iat = [timestamps[j+1] - timestamps[j] for j in range(len(timestamps) - 1)]\n",
    "        else:\n",
    "            iat = []\n",
    "        \n",
    "        # Calculate the number of successive \"KO\" statuses\n",
    "        nb_succesive_KO = 0\n",
    "        current_ko_streak = 0\n",
    "        for status in status_list:\n",
    "            if status == \"KO\":\n",
    "                current_ko_streak += 1\n",
    "                if current_ko_streak > 1:\n",
    "                    nb_succesive_KO += 1\n",
    "            else:\n",
    "                current_ko_streak = 0\n",
    "\n",
    "        # Calculate average, standard deviation, min, max of IAT\n",
    "        avg_iat = sum(iat) / len(iat) if iat else 0\n",
    "        std_iat = (sum((x - avg_iat) ** 2 for x in iat) / len(iat)) ** 0.5 if iat else 0\n",
    "        min_iat = min(iat) if iat else 0\n",
    "        max_iat = max(iat) if iat else 0\n",
    "        \n",
    "        # Calculate character distribution in FQDNs\n",
    "        char_distribution = Counter()\n",
    "        for fqdn in fqdn_list:\n",
    "            char_distribution.update(fqdn)\n",
    "        num_digits = sum(char_distribution[c] for c in char_distribution if c.isdigit())\n",
    "        num_alpha = sum(char_distribution[c] for c in char_distribution if c.isalpha())\n",
    "        num_special = sum(char_distribution[c] for c in char_distribution if not c.isalnum())\n",
    "        \n",
    "        # Calculate FQDN entropy\n",
    "        fqdn_entropies = [calculate_entropy(fqdn) for fqdn in fqdn_list]\n",
    "        avg_fqdn_entropy = sum(fqdn_entropies) / len(fqdn_entropies) if fqdn_entropies else 0\n",
    "        \n",
    "        # Calculate frequency of status codes\n",
    "        status_counts = Counter(status_list)\n",
    "        \n",
    "        # Calculate request rate\n",
    "        duration = (max(timestamps) - min(timestamps)) if timestamps else 1\n",
    "        request_rate = len(timestamps) / duration if duration > 0 else 0\n",
    "        \n",
    "        # Calculate temporal patterns (example: moving average of IATs)\n",
    "        temporal_patterns = sum(iat) / len(iat) if len(iat) > 0 else 0\n",
    "        \n",
    "        features.append((\n",
    "            id, nb_succesive_KO, avg_iat, std_iat, min_iat, max_iat,\n",
    "            num_digits, num_alpha, num_special, avg_fqdn_entropy,\n",
    "            request_rate, temporal_patterns, output_status\n",
    "        ))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c72441a-cafd-4643-bbde-c66c9ab07b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n",
      "  ID                                          Timestamp  \\\n",
      "0  1  [0, 54955, 104344, 128879, 157872, 199433, 252...   \n",
      "1  2  [0, 51459, 92748, 109403, 137506, 157103, 1832...   \n",
      "2  3  [0, 48919, 82205, 122029, 176252, 231081, 2333...   \n",
      "3  4  [0, 13702, 62165, 73898, 100539, 138132, 17751...   \n",
      "4  5  [0, 17744, 44416, 89472, 93368, 136703, 141995...   \n",
      "\n",
      "                                               FQDNs  \\\n",
      "0  [mtiwodiwmjqandi1nzk1.com, mtiwodiwmjqantqwmji...   \n",
      "1  [mtiwodiwmjqanjg2mdg0.com, mtewodiwmjqanju5mta...   \n",
      "2  [mtiwodiwmjqaotcwnzm3.com, mtewodiwmjqaotewmte...   \n",
      "3  [baloncesto ..at, centelladorinso..nato, jimio...   \n",
      "4  [qjnmssnpvqccb.com, mfpzomfjpmuts.gov, ugprafa...   \n",
      "\n",
      "                                              Status Output  \n",
      "0  [KO, KO, KO, KO, OK, OK, KO, KO, KO, KO, OK, O...    dga  \n",
      "1  [KO, KO, KO, KO, OK, OK, KO, KO, KO, KO, OK, O...    dga  \n",
      "2  [KO, KO, KO, KO, OK, OK, KO, KO, KO, KO, OK, O...    dga  \n",
      "3  [KO, KO, KO, KO, OK, OK, KO, KO, KO, KO, OK, O...    dga  \n",
      "4  [KO, KO, KO, KO, OK, OK, KO, KO, KO, KO, OK, O...    dga  \n",
      "\n",
      "Features:\n",
      "  Scenario  Nb Successive KO       Avg IAT       Std IAT  Min IAT  Max IAT  \\\n",
      "0        1                39  29658.460526  16056.517768      337    54955   \n",
      "1        2                45  28712.318182  16292.489975      221    55387   \n",
      "2        3                21  31812.925000  16822.895116       36    55768   \n",
      "3        4                17  27480.393939  15991.081249     1899    55030   \n",
      "4        5                 9  26552.687500  14905.841484     3896    54874   \n",
      "\n",
      "   Num Digits  Num Alpha  Num Special  Avg FQDN Entropy  Request Rate  \\\n",
      "0          30       1342           77          3.438927      0.000034   \n",
      "1          66       1628           89          3.520563      0.000035   \n",
      "2          35        740           42          3.475435      0.000032   \n",
      "3          26        427           71          3.330075      0.000037   \n",
      "4           0        254           18          3.364908      0.000040   \n",
      "\n",
      "   Temporal Patterns Output  \n",
      "0       29658.460526    dga  \n",
      "1       28712.318182    dga  \n",
      "2       31812.925000    dga  \n",
      "3       27480.393939    dga  \n",
      "4       26552.687500    dga  \n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    log_file_path = 'dga_simulation_log.txt'  \n",
    "    data = load_log_file(log_file_path)\n",
    "    dataset = create_dataset(data)\n",
    "    features = calculate_features(dataset)\n",
    "    \n",
    "    dataset_df = pd.DataFrame({\n",
    "        'ID': dataset['ID'],\n",
    "        'Timestamp': dataset['Timestamp'],\n",
    "        'FQDNs': dataset['FQDNs'],\n",
    "        'Status': dataset['Status'],\n",
    "        'Output': dataset['Output'] \n",
    "    })\n",
    "    \n",
    "    features_df = pd.DataFrame(features, columns=[\n",
    "        \"Scenario\", \"Nb Successive KO\", \"Avg IAT\", \"Std IAT\", \"Min IAT\", \"Max IAT\", \n",
    "        \"Num Digits\", \"Num Alpha\", \"Num Special\",\n",
    "        \"Avg FQDN Entropy\", \"Request Rate\", \"Temporal Patterns\", \"Output\"\n",
    "    ])\n",
    "\n",
    "    print(\"Dataset:\")\n",
    "    print(dataset_df.head())\n",
    "    print(\"\\nFeatures:\")\n",
    "    print(features_df.head())\n",
    "    \n",
    "    dataset_df.to_csv('dataset.csv', index=False)\n",
    "    features_df.to_csv('features.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbeb2b-b234-48f1-b06e-8f87f6c426b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
